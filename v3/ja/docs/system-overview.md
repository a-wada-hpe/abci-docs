# ABCIシステムの概要

## システム全体概要 {#system-architecture}

ABCIシステムは、合計6,128基のNVIDIA H200 GPUアクセラレーターを備えた766台の計算ノード(H)を始めとする計算リソース、物理容量75PBのストレージ、これらを高速に結合するInfiniBandネットワーク、ファイアウォールなどからなるハードウェアと、これらを最大限活用するためのソフトウェアから構成されます。また、ABCIシステムは学術情報ネットワークSINET6を利用して、400 Gbpsでインターネットに接続しています。

## 計算リソース {#computing-resources}

ABCIシステムの計算リソースの一覧を以下に示します。

| 項目 | ホスト名 | 説明 | ノード数 |
|:--|:--|:--|:--|
| アクセスサーバ | *as.v3.abci.ai* | 外部からアクセスするためのSSHサーバ | 2 |
| インタラクティブノード | *login* | ABCIシステムのフロントエンドとなるログインサーバ | 5 |
| 計算ノード(H) | *hnode001*-*hnode766* | NVIDIA H200 GPUを搭載するサーバ | 766 |

!!! note
    運用・保守上の合理的理由により、計算リソースの一部が提供されない場合があります。

このうち、インタラクティブノードと計算ノード(H)は、それぞれInfiniBand HDR (200 Gbps)を備えており、後述のストレージシステムにInfiniBandスイッチを介して接続されます。
また、計算ノード(H)は追加でInfiniBand NDR (200 Gbps)を8ポート備えており、計算ノード(H)間がInfiniBandスイッチにより接続されます。

以下ではこれらのノードの詳細を示します。

### インタラクティブノード {#interactive-node}

ABCIシステムのインタラクティブノードは、HPE ProLiant DL380 Gen11で構成されています。
Intel Xeon Platinum 8468プロセッサーを2基搭載し、約1024 GBのメインメモリが利用可能です。

インタラクティブノードの構成を以下に示します。

| 項目 | 説明 | 個数 |
|:--|:--|:--|
| CPU | Intel Xeon Platinum 8468 Processor 2.1 GHz, 48 Cores | 2 |
| Memory | 64 GB DDR5-4800 | 16 |
| SSD | SAS SSD 960 GB | 2 |
| SSD | NVMe SSD 3.2 TB | 4 |
| Interconnect | InfiniBand HDR (200 Gbps) | 2 |
| | 10GBASE-SR | 1 |

ABCIシステムのフロントエンドであるインタラクティブノードには、アクセスサーバを経由したSSHトンネリングを用いてログインします。インタラクティブノードではコマンドの対話的実行が可能であり、プログラムの作成・編集、ジョブ投入・表示などを行います。インタラクティブノードにはGPUが搭載されていませんが、インタラクティブノードで計算ノード向けのプログラム開発も可能です。

ログイン方法の詳細は[ABCIの利用開始](getting-started.md)、ジョブ投入方法の詳細は[ジョブ実行](job-execution.md)をそれぞれ参照してください。

!!! warning
    インタラクティブノードのCPUやメモリなどの資源は多くの利用者で共有するため、高負荷な処理は行わないようにしてください。高負荷な前処理、後処理を行う場合は、計算ノードを利用してください。
    インタラクティブノードで高負荷な処理を行った場合、システムにより処理が強制終了されますのでご注意ください。

### 計算ノード {#compute-node}

計算ノード向けのプログラムを実行するには、バッチジョブもしくはインタラクティブジョブとしてジョブ管理システムに処理を依頼します。インタラクティブジョブでは、プログラムのコンパイルやデバッグ、対話的なアプリケーション、可視化ソフトウェアの実行が可能です。詳細は[ジョブ実行](job-execution.md)を参照してください。

#### 計算ノード(H) {#compute-node-h}

計算ノード(H)は、HPE Cray XD670で構成されています。
計算ノード(H)は、Intel Xeon Platinum 8558プロセッサーを2基、NVIDIA H200 GPUアクセラレーターを8基搭載しています。システム全体では、総CPUコア数は73,536コア、総GPU数は6,128基となります。

計算ノード(H)の構成を以下に示します。

| 項目 | 説明 | 個数 |
|:--|:--|:--|
| CPU | Intel Xeon Platinum 8558 2.1GHz, 48cores | 2 |
| GPU | NVIDIA H200 SXM 141GB | 8 |
| Memory | 64 GB DDR5-5600 4400 MHz | 32 |
| SSD | NVMe SSD 7.68 TB | 2 |
| Interconnect | InfiniBand NDR (200 Gbps) | 8 |
| | InfiniBand HDR (200 Gbps) | 1 |
| | 10GBASE-SR | 1 |


## ストレージシステム {#storage-systems}

ABCIシステムは、人工知能やビッグデータ応用に用いる大容量データを格納するためのストレージシステムを3基備えており、これらを用いて共有ファイルシステムを提供しています。下記の/home、 /groupsおよび今後に提供予定のストレージ<!-- 、 /groups_s3 -->の合算で約75 PBの実効容量があります。

| 構成 | ストレージシステム | メディア | 用途 |
|:--|:--|:--|:--|
| 1 | DDN ES400NVX2 | 61.44TB NVMe SSD x256 | ホーム領域(/home) |
| 2 | DDN ES400NVX2 | 61.44TB NVMe SSD x1280 | グループ領域(/groups) |
<!--| 3 | DDN ES400NVX2 | 30.72TB NVMe SSD x48 | ABCIオブジェクト領域(/groups_s3) |-->

上記のストレージシステムを用いて、ABCIシステムが提供している共有ファイルシステムの一覧を以下に示します。

| 用途 | マウントポイント | 実効容量 | ファイルシステム | 備考 |
|:--|:--|:--|:--|:--|
| ホーム領域 | /home | 10 PB | Lustre |  |
| グループ領域 | /groups | 63 PB | Lustre |  |
| ABCIクラウドストレージ | /groups_s3 | 1PB | Lustre |  |

データ移行目的のために、下記のファイルシステムがマウントされています。

| 用途 | マウントポイント | 実効容量 | ファイルシステム | 備考 |
|:--|:--|:--|:--|:--|
| アーカイブ | /groups-2.0 | 10.8 PB | Lustre | 読み取り専用。ABCI 2.0で利用されていたグループ領域 |


インタラクティブノード、計算ノードは、共有ファイルシステムをマウントしており、利用者は共通のマウントポイントからこれらのファイルシステムにアクセスすることができます。

これ以外に、これらのノードはそれぞれローカルスクラッチ領域として利用可能なローカルストレージを搭載しています。以下に一覧を示します。

| ノード種類 | マウントポイント | 容量 | ファイルシステム | 備考 |
|:--|:--|:--|:--|:--|
| インタラクティブノード | /local | 12 TB | XFS | |
| 計算ノード(H) | /local1 | 7 TB | XFS |  |
|               | /local2 | 7 TB | XFS | BeeGFS含む |


ストレージのサービス仕様を以下に示します。

| ストレージ | 初期容量 | 容量の上限 | inode数 | inode数の上限 | 課金ポイント(標準利用) | 課金ポイント(開発加速利用) |
| :- | :- | :- | :- | :- | :- | :- |
| /home | 2TB | 2TB | | | 無償 | 無償 |
| /groups | 0TB | 1000TB | 2億 | 6億 | 5ポイント/TB・月 | 2.5ポイント/TB・月 |
| /groups-2.0 | - | - | - | - | 無償 | 無償 |
| クラウドストレージ | 0TB | 50TB | - | - | 5ポイント/TB・月| 2.5ポイント/TB・月|

!!! note
    * ストレージサービスでは、1TBにつき、1,099,511,627,776 bytesの容量を割り当てます。
    * /homeファイルシステムは全利用者で共有されており、その総inode個数は約250億個です。個々の利用者の/homeディレクトリには、inode数の制限は設けておりません。
    * /groupsは利用者ポータル[^footnote01]から容量を1,000TBまで増量できます。
    * /groupsにおいて、1,000TBを超える容量が必要な場合やinode数の上限を引き上げたい場合はメールによる申請が必要です。申請方法については[グループ領域の上限引き上げ申請](requests/group-area-quota-increase.md)を参照してください。
    * /groups-2.0は2025年9月末で提供を終了します。詳細は[今後のストレージサービスのお知らせ](https://abci.ai/news/2024/09/04/ja_storage_after_nov2024.html)を参照してください。

[^footnote01]: 利用者ポータルは2025年3月18日より提供開始を予定しております。

## ソフトウェア {#software}

ABCIシステムで利用可能なソフトウェア一覧を以下に示します。

| Category | Software | Interactive Node | Compute Node |
|:--|:--|:--|:--|
| OS | Rocky Linux | - | 9.4 |
| OS | Red Hat Enterprise Linux | 9.4 | - |
| Job Scheduler | Altair PBS Professional | 2022.1.6 | 2022.1.6 |
| Development Environment | CUDA Toolkit | 11.8.0<br>12.0.1<br>12.1.1<br>12.2.2<br>12.3.2<br>12.4.1<br>12.5.1<br>12.6.1<br>12.8.1<br>12.9.1 | 11.8.0<br>12.0.1<br>12.1.1<br>12.2.2<br>12.3.2<br>12.4.1<br>12.5.1<br>12.6.1<br>12.8.1<br>12.9.1 |
| | Intel oneAPI<br>(compilers and libraries) | 2024.2.1 | 2024.2.1 |
| | GCC | 11.5.0<br>13.2.0 | 11.4.1<br>13.2.0 |
| | Python | 3.9.21<br>3.12.9<br>3.13.2 | 3.9.21<br>3.12.9<br>3.13.2 |
| | Ruby | 3.0.7 | 3.0.4 |
| | R | 4.5.1 | 4.5.1 |
| | Java | 17.0.16 | 17.0.16 |
| | Scala | 3.5.2 | 3.5.2 |
| | Perl | 5.32.1 | 5.32.1 |
| | Go | 1.24.6 | 1.24.4 |
| File System | DDN Lustre | 2.14.0_ddn196 | 2.14.0_ddn196 |
| | BeeOND | - | 7.4.5 |
| Object Storage | s3cmd | 2.4.0 | 2.4.0 |
| Container | SingularityCE | 4.1.5 | 4.1.5 |
| MPI | Intel MPI | 2021.13 | 2021.13 |
| | hpcx | 2.20 | 2.20 |
| | hpcx-debug | 2.20 | 2.20 |
| | hpcx-mt | 2.20 | 2.20 |
| | hpcx-prof | 2.20 | 2.20 |
| Library | cuDNN | 9.5.1<br>9.12.0 | 9.5.1<br>9.12.0 |
| | NCCL | 2.23.4-1<br>2.25.1-1 | 2.23.4-1<br>2.25.1-1 |
| | gdrcopy | 2.4.1 | 2.4.1 |
| | UCX | 1.17 | 1.17 |
| | Intel MKL | 2024.2.1 | 2024.2.1 |
| Utility | aws-cli | 1.29.62 | 1.29.62 |
| | s3fs-fuse | 1.94 | 1.94 |
| | rclone | 1.70.3 | 1.70.3 |
